\documentclass[12pt]{report}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{amsfonts} 
\usepackage{amsmath} 
\usepackage[spanish]{babel}
\usepackage[T1]{fontenc}
\usepackage{tocloft} % Paquete para personalizar la tabla de contenidos
\pagestyle{fancy}
\fancyhf{}
\fancyhf{}
\rhead{}
\lhead{Universidad de la Habana}
\rfoot{\thepage}

% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

% Configuración de la tabla de contenidos
\setcounter{secnumdepth}{3} % Numerar hasta subsubsecciones
\setcounter{tocdepth}{3}    % Incluir hasta subsubsecciones en el índice


\begin{document}
%
\title{Análisis Comparativo entre la programación entera y la programación de satisfacción de restricciones}

%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Javier Rodríguez Sánchez}

\maketitle 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                            ABSTRACT                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
The abstract should briefly summarize the contents of the paper in
15--250 words.

\end{abstract}
%

\newpage

% Tabla de contenidos
\tableofcontents

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                        INTRODUCCIÓN                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introducción}

La formulación de problemas reales en diversos campos de estudio frecuentemente se encuentra condicionada por la necesidad de satisfacer un conjunto de restricciones. Estas limitaciones, que pueden ser tanto naturales como impuestas por el contexto del problema, son fundamentales para el desarrollo de soluciones efectivas. Por ejemplo, en la naturaleza, la velocidad de la luz establece un límite inquebrantable para todo objeto en movimiento; mientras que en biología, la configuración nativa de una proteína depende de combinaciones específicas de aminoácidos. En el ámbito matemático, especialmente en teoría de conjuntos y lógica, se han desarrollado lenguajes y herramientas que permiten representar y procesar estas restricciones a través de ecuaciones e inecuaciones. \\

La mayoría de los problemas prácticos que requieren solución son problemas discretos con restricciones, donde las variables están limitadas a dominios finitos. Sin embargo, la cantidad de variables involucradas puede ser considerable, lo que genera combinaciones exponenciales y, por ende, una explosión combinatoria (un crecimiento rápido e incontrolado en el número de posibles combinaciones) en la búsqueda de soluciones viables. La versión más compleja de estos problemas se agrupa bajo el concepto de optimización discreta, que pertenece a la categoría NP-completa. Esta complejidad ha impulsado el desarrollo de técnicas computacionales para mejorar la eficiencia en su resolución.  \\

La programación entera(IP) se erige como una herramienta crucial en la resolución de problemas que requieren decisiones discretas, donde las variables de decisión están restringidas a valores enteros. Esta técnica es un subconjunto de la programación matemática y se utiliza ampliamente en diversas aplicaciones prácticas, desde la gestión de la cadena de suministro hasta la planificación de proyectos y la asignación de recursos. La formulación de un problema de optimización entera implica definir una función objetivo que se desea maximizar o minimizar, junto con un conjunto de restricciones que limitan las posibles soluciones.  \\

Además, en las últimas décadas, el campo de la Inteligencia Artificial (IA) ha visto emerger nuevas formas de modelar problemas de satisfacción de restricciones, especialmente dentro del ámbito de la lógica computacional. Esto ha dado lugar a la programación de satisfacción de restricciones (CSP), que se presenta como una vía alternativa a la programación entera.  \\

La presente investigación propone identificar qué paradigma utilizar para ganar eficiencia y aplicabilidad en las diferentes clases de problemas discretos, dadas las especificaciones que caracterizan a dicha clase.  \\

El objetivo general de esta tesis es comparar la eficiencia temporal de los paradigmas de programación entera y programación de satisfacción de restricciones en la solución de diferentes clases de problemas discretos. Para esto, se seleccionarán diferentes clases de problemas discretos que permitan evidenciar las diferencias entre ambos paradigmas, de los cuales se identificarán rasgos significativos que puedan afectar el rendimiento en uno u otro paradigma. Luego, se propondrán dos modelaciones diferentes, una como un problema de satisfacción de restricciones y otra como modelo de optimización entera. Se propone luego simular diferentes especificaciones de las clases de problemas para poder comparar los resultados de ambos modelos. Una vez con los resultados, se buscará una correlación entre las características presentes en el problema y el rendimiento temporal.\\

La tesis consta de otros cuatro capítulos. El capítulo 2 se presentará el marco teórico de ambos paradigmas, empezando por la programación entera en la sección 2.1 y la programación de satisfacción de restricciones en la sección 2.2. En el capítulo 3 se hará referencia a las clases de problemas analizadas, y a los medios de implementación que fueron utilizados. Los resultados alcanzados serán analizados en el capítulo 4, y las conclusiones serán exhibidas en el capítulo 5. Además, al final de la tesis se podrán ver los modelos que fueron utilizados por ambos paradigmas en la implementación de las soluciones.\\

Esta tesis se desarrolla en la Facultad de Matemática y Computación de la Universidad de La Habana.  \\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                        MARCO TEÓRICO                        %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Marco Teórico}

Un problema de optimización consiste en encontrar una asignación de valores a un conjunto de variables de forma que cumplan un conjunto de restricciones y maximicen o minimicen una función de costo. Estos se pueden clasificar de acuerdo con los valores que pueden tener las variables que intervienen. Si el dominio de alguna de sus variables es el conjunto de los enteros, estamos en un problema de optimización en enteros mixta. Dentro de la anterior categoría, se dice que se trabaja en enteros puros si todas sus variables son de dominio entero. Un caso especial en la anterior categoría es cuando todas las variables son binarias (pueden adoptar solamente 0 o 1 como valores).

Estos problemas son fundamentales en diversas áreas como logística, planificación, asignación de tareas y, de forma general, todos aquellos escenarios donde se dispone de recursos limitados para resolver determinada situación. La naturaleza combinatoria de estos problemas a menudo implica que el número de soluciones posibles crezca exponencialmente con el tamaño del problema, lo que potencia la necesidad de descubrir nuevas técnicas y heurísticas para mejorar la eficiencia de los algoritmos exactos que garanticen soluciones óptimas. Dicha eficiencia depende, en primer lugar, de cómo se construyen los modelos y, en segundo lugar, de los métodos computacionales utilizados. 

Para esto, se puede seguir dos paradigmas diferentes: la programación entera y la programación de satisfacción de restricciones.

\section{Programación en enteros}

La programación en enteros es un conjunto de herramientas ampliamente utilizadas para resolver el siguiente problema: cuál es el máximo/mínimo que alcanza la función $c^Tx+d^Ty$ sujeto a las restricciones: $Ax\leq p$, $By\leq q$, $x\geq 0$, $y\geq 0$, $x\in \mathbb{R} ^n$, $y\in \mathbb{Z}^m$.  


\subsection{Programación lineal como base de la programación en enteros}

El paradigma antes mencionado es una extensión de la programación lineal, ya que, de forma general, resolver un problema de programación en enteros requiere resolver uno o varios problemas lineales.\\

El principal algoritmo utilizado para resolver un problema de optimización lineal es el método Simplex. Se centra en la resolución de los modelos en su llamada forma estándar: $min$ $c^Tx$ $s.a.$ $Ax=b$, $x\geq 0$. Es importante notar que todo modelo puede llevarse a forma estándar siguiendo los siguientes pasos:
\begin{itemize}
    \item Si el objetivo es maximizar $c^Tx$, este es equivalente a minimizar $-c^Tx$.
    \item Si hay una restricción de la forma $a^Tx\leq b$, entonces se puede introducir una variable nueva $x^h=b-a^Tx$, de forma que la restricción se puede escribir como $a^Tx+x^h=b$. Homólogamente, si existe una restricción de la forma $a^Tx\geq b$ se puede redefinir como $a^Tx-x^h=b$. Las nuevas variables se suelen llamar variables de holguras.
    \item Si una variable $x_i$ es irrestricta en signo, esta se puede expresar como la resta de dos variables positivas $x_i^+$ y $x_i^-$.\\
\end{itemize}

Ejemplo:
$$max \text{ }z= -3x_1-x_2+x_3$$
$$s.a.$$
$$x_1+2x_2+x_3\geq 5$$
$$x_1-3x_2+5x_3\geq -10$$
$$x_1,x_2\geq 0$$\\

Luego de estandarizar este problema obtenemos:
$$min \text{ }z= 3x_1+x_2-x_3^++x_3^-$$
$$s.a.$$
$$x_1+2x_2+x_3^+-x_3^--x_1^h=5$$
$$-x_1+3x_2-5x_3^++5x_3^-+x_2^h=10$$
$$x_1,x_2,x_3^+,x_3^-,x_1^h,x_2^h\geq 0$$\\

Se dice que $x$ es solución factible de un problema lineal en su forma estándar si $Ax=b$. Si $x$ tiene un número de componentes nulas menor o igual al número de restricciones, se dice que $x$ es solución factible básica. De estas definiciones se deriva el Teorema Fundamental de la Programación Lineal, el cual garantiza que si existe una solución factible óptima, entonces también existe una solución factible básica óptima. Este teorema es la base del método Simplex, que consiste en explorar únicamente las soluciones factibles básicas del problema en búsqueda del óptimo.\\

El primer paso del algoritmo es encontrar una solución factible básica. Para eso se selecciona una cantidad de componentes de $x$ igual a la cantidad de restricciones. Sea $x_B$ las componentes elegidas y $x_r$ el resto. Entonces la matriz $A$ de la forma estándar del problema se puede descomponer en dos matrices $B$ y $C$ de forma que:

$$Bx_B+Cx_r=b$$

Luego, se multiplican ambos miembros por $B^{-1}$, resultando:

$$x_B+Rx_r=y$$

Donde $R=B^{-1}C$ y $y=B^{-1}b$.\\

Esta es la llamada forma explícita del problema, donde a los componentes de $x_B$ se les conoce como componentes básicos de la solución. Y permite realizar la asignación $x_B=y, x_r=0$. Garantizando una solución básica. \\

En la forma explícita es importante asegurar que $y\geq 0$. Esto, sumado a la dificultad computacional de calcular la inversa de una matriz, se suele usar el método Simplex de dos fases para la obtención de la primera solución factible básica.\\

Una vez con la solución factible básica inicial, el algoritmo compara las evaluaciones entre la solución actual y las adyacentes (aquellas que se obtienen al cambiar un componente básico por uno no básico). Si ninguna solución adyacente tiene una evaluación menor que la actual, entonces se ha encontrado una solución óptima, lo cual se asegura debido a la convexidad del conjunto de soluciones factibles. De lo contrario, se cambia de solución factible básica y se repite el proceso.\\

Aunque el método Simplex tiene un tiempo de ejecución exponencial en el peor de los casos, en la práctica, es muy eficiente y rápido para la mayoría de los problemas reales, siendo la herramienta por excelencia para su solución. 

\subsection{Planos cortantes}

En el siguiente problema de optimización:

$$max \text{ } 20x_1+10x_2+x_3$$
$$s.a.$$
$$3x_1+2x_2+10x_3=10$$
$$2x_1+4x_2+20x_3=15$$
$$x_1,x_2,x_3\geq 0$$\\

La solución de este problema es: $x_1 = \frac54,x_2 = \frac{25}{8},x_3 = 0$. Sin embargo, si las variables involucradas fueran enteras, esta solución no es factible. La solución redondeada es: $x_1 = 1,x_2 = 3,x_3 = 0$, con valor de la función objetivo igual a 50. Sin embargo, la solución $x_1 = 2,x_2 = 2,x_3 = 0$, proporciona un valor de la función objetivo igual a 60. Por otra parte, la solución redondeada no satisface las restricciones del problema. Por tanto, resulta de interés diseñar algoritmos que manejen la condición de las variables de ser enteras.\\

Una forma de extender la programación lineal a la programación entera podría plantearse como encontrar la menor cobertura convexa que contiene todas las asignaciones satisfacibles del problema. Si $S$ es el conjunto de asignaciones reales posibles del problema, $conv(S)$ se denota como la menor cobertura convexa del mismo. Ejemplo:

$$max \text{ } 5x_1+6x_2$$
$$s.a.$$
$$10x_1+14x_2 \leq  35$$
$$x_1,x_2\geq 0$$
$$x_1,x_2\in\mathbb{Z}$$\\

La menor cobertura convexa es:

$$conv(S)=\{(x_1,x_2)|x_1+x_2\leq 3 \land x_1+2x_2\leq 4 \land x_1,x_2\geq 0\}$$

Si se utiliza Simplex al nuevo problema:

$$max \text{ } 5x_1+6x_2$$
$$s.a.$$
$$(x,y) \in conv(S)$$
$$x_1,x_2\in\mathbb{Z}$$

Se obtiene la solución $x_1=2, x_2=1$.\\

En la práctica, buscar la menor cobertura convexa es difícil e ineficiente. Sin embargo, es posible calcular algunas de las restricciones de una cobertura convexa que no descarte soluciones enteras y excluya soluciones reales a conveniencia. Se trata de trabajar con un conjunto convexo $Q$ tal que $conv(S)\subseteq Q\subseteq S$. Si en la asignación óptima de $Q$ las variables enteras poseen valores enteros, entonces esa es la solución del problema. De lo contrario, se busca un nuevo conjunto convexo $Q'$ que no incluya dicha solución, tal que $conv(S)\subseteq Q'\subseteq Q$. Este nuevo conjunto convexo se obtiene a partir de la introducción de una nueva restricción que no excluye variables reales. Y se repite el proceso.\\

Todos los procedimientos basados en la explicación anteriormente planteada son conocidos como métodos de planos cortantes, y a las restricciones que se agregan se les denomina corte. Estos métodos comienzan con una relajación inicial de las restricciones de números enteros, lo que da como resultado una solución fraccionaria. Posteriormente, se añaden iterativamente cortes para reforzar la relajación hasta que se obtiene una solución entera.\\

Existen varias técnicas para generar planos de corte, pero la mayoría se deriva del corte fundamental, y a partir de este se derivan los más usados, como el corte de Gomory, el corte Primal Todo Entero y el corte  de Chvátal-Gomory.\\


\subsection{Ramificación y acotación}

Sea un problema de optimización en enteros tal que, al resolver el problema relajado, una de sus variables enteras $x_i$ tenga un valor real $p$. Como su valor puede ser entero, se cumple que $x \leq  [p] \lor  x \geq  [p]+1$. Sabiendo esto, se pueden resolver 2 nuevos problemas de optimización, con cada uno con las restricciones del problema original adicionando las restricciones anteriores respectivamente a cada uno. Finalmente, el óptimo será el menor (si se está minimizando; de lo contrario, será el mayor) de los óptimos de ambas ramas. El método descrito es conocido como Ramificación y acotación. \\

Por ejemplo:

$$max \text{ } x_1 + x_2$$
$$s.a.$$
$$2x_1 + 2x_2 \geq  3$$
$$-2x_1 + 2x_2 \leq  3$$
$$4x_1 + 2x_2 \leq  19$$
$$x_1, x_2 \geq  0$$
$$x_1, x_2 \in \mathbb{Z}$$

Solución óptima: $x_1=2.67, x_2=4.16, Objective=6.83$.\\

Entonces, el problema se divide en dos subproblemas distintos: uno con la restricción extra $x_1\leq 2$ (Caso 1) y otro con la restricción extra $x_1\geq 3$ (Caso 2).\\

Para el caso 1, la solución óptima es: $x_1=2, x_2=3.5, Objective=5.5$

Para el caso 2 esta es: $x_1=2, x_2=3.5, Objective=6.5$.\\

En este caso se puede seguir ramificando por ambas vías. Específicamente, si ramificamos el caso 2, este se dividiría en el caso donde $x_2\geq 4$ y el caso donde $x_2\leq 3$. Finalmente, tras otras dos ramificaciones, se puede llegar a que el óptimo es $x1=3, x2=3, Objective=6$.\\

Ramificación y acotación es una técnica que permite explorar diferentes posibilidades de solución dividiendo el problema en subproblemas más manejables, mientras que los planos cortantes ayudan a eliminar soluciones no viables, mejorando la eficiencia del proceso de búsqueda. Ambas metodologías, aunque pueden ser aplicadas por separado, se complementan eficazmente en la búsqueda de soluciones óptimas. Dicha combinación es conocida como \textit{Branch and Cut}. 

\subsection{Uso de variables binarias para la modelación de problemas}


Es fundamental identificar qué problemas pueden ser representados como problemas de programación entera. Para ello, resulta interesante explorar cómo diversas restricciones de la lógica de predicados pueden ser modeladas en este contexto. Al comprender esta relación, se puede traducir enunciados lógicos complejos en formulaciones matemáticas que se pueden resolver mediante técnicas de optimización discreta, ampliando así el alcance de los problemas que podemos abordar.\\

Suponga que se desea introducir las siguientes restricciones:

$$ \sum_j a_{ij}x_j \leq  b_i \implies  \delta_i = 1$$
$$  \delta_i = 1 \implies  \sum_j a_{ij}x_j \leq  b_i$$

Si estas restricciones se logran, se podría saber cuántas restricciones se cumplen en un modelo, haciendo bisección entre una restricción y una variable binaria.\\

Para la primera fórmula, al aplicar contrarrecíproco, se quiere que $\sum_j a_{ij}x_j > b_i$, pero si $\exists m:\sum_j a_{ij}x_j\geq  m$ , entonces se puede crear la restricción $\sum_j a_{ij}x_j \geq  b_i+\epsilon+(m-b-\epsilon)\delta_i$. De esa forma, si $\delta_i=1$ es una restricción redundante, si $\delta_i=0$ entonces fuerza a incumplir la restricción objetivo.\\

Para la segunda, si $\exists M:\sum_j a_{ij}x_j\leq  M$ entonces se puede introducir la restricción $\sum_j a_{ij}x_j \leq  M-(M-b_i)\delta_i$. \\

Luego, si no existieran dichos valores(máximos o mínimos alcanzables), entonces se dice que el problema no es MIP representable. Un ejemplo de esto sería: $x=0\lor  y=0$.\\

Una vez haciendo biyección entre variables lógicas y restricciones lineales, se pueden hacer operaciones lógicas elementales:

$$\delta_1 \lor  \delta_2:\delta_1+\delta_2\geq 1$$
$$\delta_1 \land \delta_2:\delta_1+\delta_2=2$$
$$\neg\delta_1 :\delta_1=0$$
$$\delta_1 \implies  \delta_2:\delta_1\leq  \delta_2$$
$$\delta_1 \iff \delta_2:\delta_1=\delta_2$$

De esta forma se podrían modelar problemas escritos en formas normales conjuntivas y disyuntivas.

\section{Programación de satisfacción de restricciones}

Una forma de analizar un problema de optimización es como un problema de satisfacción de restricciones, que consiste en una tupla $(V,D,C)$ donde $V$ es un conjunto de variables, $D=\{D_v|v\in V\}$ es el conjunto de los conjuntos de los posibles valores que pueden tomar cada variable, y $C$ es un conjunto finito de restricciones de la forma $(R_i,S_i)$, con $S_i$ es un subconjunto ordenado de $V$ y $R_i$ es una relación de tamaño $|S_i|$. Una solución es una asignación a cada variable que pertenece a $V$ con uno de sus correspondientes valores en $D$ tal que se cumplan todas las restricciones en $C$.

La programación de satisfacción de restricciones (CSP) es aquella especializada en resolver este tipo de problemas. Algunas de las operaciones (por ejemplo, la ramificación) utilizadas son similares a las de IP, y tiene muchas características en común con los procedimientos de reducción que ahora se usan comúnmente para preprocesar modelos. Este enfoque no está concebido como un método de optimización propiamente, aunque se puede adaptar a él haciendo que el objetivo, con límites cada vez más estrictos, sea una restricción.

\subsection{SAT como base de la satisfacción de restricciones}

No siempre es obvio, con un solo problema, hasta qué punto se utiliza la lógica o se utilizan métodos más analíticos. Sin embargo, hay una gran ventaja en poder moverse entre los dos y reconocer las relaciones entre ellos. En este sentido, la programación entera y la lógica son simbióticas.\\

En este contexto, el problema de satisfacibilidad booleana (SAT) emerge como un caso paradigmático donde la lógica y la optimización discreta se cruzan. El Teorema de Cook, propuesto por Stephen Cook en 1971, es un hito fundamental en la teoría de la complejidad computacional, pues plantea que todo problema de la categoría NP es reducible a SAT. Este consiste en determinar, dada una fórmula lógica, si existe una interpretación de la misma tal que sea verdadera.\\ 

Todo lo anteriormente planteado permite resaltar la gran importancia que cobra la lógica en este tipo de problemas, pues es la que permite deducir enunciados a partir de otros en función de las reglas de deducción que lo conforman. Más específicamente, la lógica proposicional y la lógica de predicados proporcionan un marco teórico robusto para abordar los problemas SAT.\\

Como forma general, todo problema SAT se representa en su Forma Normal Conjuntiva(CNF) debido a las ventajas que ésta posee, y todos los cuantificadores se sitúan al principio de la expresión (\textit{Prenex Normal Form}). Es necesario señalar que toda expresión válida de la lógica de predicados puede llevarse a dicha forma.

Ejemplo:

$$\forall x(\exists y(Q(y)\lor R(x))\implies P(x))$$
Primero, se elimina la implicación utilizando la equivalencia $A→B\equiv \neg A\lor B$:
$$\forall x(\neg\exists y(Q(y)\lor R(x)) \lor  P(x))$$
A continuación, se aplica la equivalencia $\neg\exists y(A)\equiv \forall x(\neg A)$
$$\forall x(\forall y\neg(Q(y)\lor R(x)) \lor  P(x))$$
Luego, se mueven los cuantificadores hacia el exterior. Para esto último, se aplican las reglas de distribución de cuantificadores. En este caso, se puede mover el cuantificador universal hacia afuera:
$$\forall x\forall y(\neg(Q(y)\lor R(x))\lor  P(x))$$
Aplicando la equivalencia: $\neg(A\lor B)\equiv \neg A\land\neg B$
$$\forall x\forall y((\neg Q(y)\land\neg R(x))\lor  P(x))$$
Finalmente, utilizando la equivalencia $(A\land B)\lor C\equiv (A\lor C)\land(B\lor C)$
$$\forall x\forall y((\neg Q(y)\lor  P(x))\land(\neg R(x)\lor  P(x)))$$\\

Cuando los dominios de las variables son finitos, entonces cualquier fórmula de la lógica de predicados puede expresarse como una conjunción de cláusulas de la lógica proposicional. Esto es importante porque dicha lógica es consistente y completa. Se dice que un sistema es consistente si no se pueden derivar contradicciones dentro de él, es decir, no se puede demostrar que un enunciado sea verdadero y falso simultáneamente. \\

Un sistema es completo si se puede deducir la veracidad o falsedad de cualquier enunciado que pueda ser formulado en el modelo del sistema. Sin embargo, estas dos propiedades no siempre pueden coexistir en todos los sistemas. Este dilema es especialmente relevante en el contexto de la teoría de Gödel, que establece que en cualquier sistema formal consistente que sea capaz de expresar la aritmética básica, incluye proposiciones que no pueden ser ni demostradas ni refutadas dentro del propio sistema. Lo cual significa que no puede ser completo.\\

A la hora de encarar un problema de optimización usando lógica de predicados, es necesario añadir funciones, constantes y reglas que la involucren. Aunque la aritmética completa sea no decidible, hay "teorías" más pequeñas dentro de ella que sí lo son. Entre estas están la aritmética sin multiplicación y la teoría de orden lineal denso. Estas bastan para resolver cualquier modelo de optimización lineal.\\

Observe lo anteriormente planteado en el siguiente ejemplo:

$$max \text{ }z= 2x_1 + 3x_2 - x_3 $$
$$s.a.$$
$$ x_1 + x_2 \leq  3 $$
$$ -x_1 + 2x_3 \geq  -2 $$
$$ -2x_1 + x_2 - x_3 = 0 $$
$$ x_1, x_2, x_3 \in \mathbb{R}  $$

Esto planteado en lógica de predicados sería:

$\exists z,x_1,x_2,x_3 ($
$z - 2x_1 - 3x_2 + x_3 = 0$ $\land$
$ x_1 + x_2 \leq  3 $ $\land$
$ -x_1 + 2x_3 \geq  -2 $ $\land$
$ -2x_1 + x_2 - x_3 = 0 $ $\land$
$ x_1\geq  0 $ $\land$ 
$ x_2\geq  0 $ $\land$ 
$ x_3\geq  0 $ 
$)$\\

Luego, se puede despejar $x_3$ en la cuarta restricción y sustituir en el resto, eliminando así una variable del problema.

$\exists z,x_1,x_2($
$z - 2x_1 - 3x_2 + (-2x_1 + x_2) = 0$ $\land$
$ x_1 + x_2 \leq  3 $ $\land$
$ -x_1 + 2(-2x_1 + x_2) \geq  -2 $ $\land$
$ x_1\geq  0 $ $\land$ 
$ x_2\geq  0 $ $\land$ 
$ -2x_1 + x_2\geq  0 $ 
$)$\\

De forma homóloga, se puede despejar la variable $x_2$ en la primera restricción:

$\exists z,x_1 ($
$ x_1 + \frac z 2 -2x_1 \leq  3 $ $\land$
$ -5x_1 + 2(\frac z 2 -2x_1) \geq  -2 $ $\land$
$ x_1\geq  0 $ $\land$ 
$ \frac z 2 -2x_1 \geq  0 $ $\land$ 
$ -2x_1 + \frac z 2 -2x_1 \geq  0 $
$)$\\

Luego se despeja la variable $x_1$ en todas las restricciones

$\exists z (\exists x_1 ($
$ \frac z 2 - 3 \leq   x_1 $ $\land$
$ \frac z 9 + \frac 2 9 \geq  x_1 $ $\land$
$ x_1\geq  0 $ $\land$ 
$ \frac z 4 \geq  x_1 $ $\land$ 
$ \frac z 8 \geq  x_1 $ $))$\\

Notar que aquí se deduce que:

$\exists z ($
$ \frac z 2 - 3 \leq   \frac z 9 + \frac 2 9 $ $\land$
$ \frac z 2 - 3 \leq  \frac z 4  $ $\land$
$ \frac z 2 - 3 \leq  \frac z 8 $ $\land$
$ 0 \leq   \frac z 9 + \frac 2 9 $ $\land$
$ 0 \leq  \frac z 4  $ $\land$
$ 0 \leq  \frac z 8 $ 
$)$\\

Concluyendo que $-2\leq  z \leq  8$. Y como el objetivo es maximizar. Se toma $z=8$. De aquí se observa que $0\leq  x_1 \leq 1$. Que tomando a $x_1=1$ queda que $x_2=2$ y $x_3 = 0$.\\

Este procedimiento es conocido como método de eliminación de cuantificadores, que si bien no es utilizado actualmente por existir soluciones mucho más eficientes dentro de la programación lineal como el método Simplex, teóricamente demuestra que la programación lineal es una teoría decidible.

\subsection{Davis-Putnam}

El algoritmo de Davis-Putnam(DP) es un precursor de los algoritmos modernos para resolver SAT, el cual utiliza el principio de resolución. Sea una instancia de SAT en CNF, sea $p$ una variable proposicional y sean $C_1=p \lor  Q_1$  y  $C_2 = \neg p \lor  Q_2$ cláusulas del problema, con $Q_1$ y $Q_2$ disyunciones de literales. Como $(p=1)\implies  Q_2$ y $(p=0)\implies  Q_1$ se puede deducir $Q_1\lor  Q_2$. Al aplicar iterativamente resolución, podemos deducir posibles valores de variables o una contradicción. En este último caso, se dice que el problema es insatisfacible.\\ 

Observe el siguiente ejemplo: La siguiente fórmula será satisfacible:
$$(a\lor  b) \land(a\lor  \neg b) \land (\neg a\lor  c) \land(\neg a\lor  \neg c)$$

Al aplicar la regla de resolución entre las primeras dos cláusulas se obtiene la nueva restricción $(a \lor  a)$, la cual es lógicamente equivalente a $(a)$. Si se aplica nuevamente resolución entre esta cláusula y las dos últimas, se deduce $(c)$ y $(\neg c)$. Al aplicar resolución se observa que se llega a un absurdo, por lo que la fórmula nunca será satisfacible. \\

El algoritmo de Davis-Putnam sirve como base para el desarrollo de todos los algoritmos utilizados para resolver el problema SAT, estableciendo un marco teórico importante para la lógica computacional.


\subsection{Davis-Logemann-Loveland}

Por otra parte, Davis-Logemann-Loveland(DLL/DPLL) se centra en asignar iterativamente valores a las variables y deshaciendo dichas asignaciones en caso de conflicto. Este algoritmo refina Davis-Putnam e introduce técnicas cruciales como el \textit{backjumping} y el aprendizaje de cláusulas. Se basa en tres hechos: 
\begin{enumerate}
    \item Todo literal puro (se dice puro si el literal opuesto no esta presente) es asignado como cierto. Ejemplo: $(a\lor  b) \land (a\lor  \neg c) \land (d\lor  \neg c) \land (\neg d\lor  \neg b) \land (b\lor  c) $. Aquí al no estar $\neg a$ en ninguna cláusula, se puede asignar $a=1$ y reducir el problema a $(d\lor  \neg c) \land (\neg d\lor  \neg b) \land (b\lor  c) $.
    \item si una cláusula tiene todos sus literales negados excepto uno este último debe ser cierto. Ejemplo $(a \lor  b \lor  c)\land(a\lor \neg b\lor \neg c)\land(\neg a\lor  b\lor \neg c) \land(\neg a\lor  \neg b\lor  c).$ Si se hace la asignación parcial $a=1, \neg c=1$, entonces la tercera clausula $(\neg a\lor  \neg b\lor  c)$ solo puede cumplirse si $\neg b=1$.
    \item Si todos los literales de una cláusula están negados, entonces la asignación hecha hasta dicho punto es falsa.\\
\end{enumerate}


El algoritmo tiene 5 etapas:
\begin{enumerate}
    \item Preprocesamiento: Aquí se buscan todos los literales puros y se les asigna valor 1.
    \item Ramificación: Aquí se asigna valor a un literal. Una buena heurística a la hora de decidir que literal escoger es \textit{Variable State Independent Decaying Sum} (VSIDS), que consiste en asignar un número a cada literal, el cual empieza siendo la cantidad de cláusulas en las que aparece, se divide entre una constante (usualmente 2) periódicamente y se le suma 1 cada vez que aparece en una cláusula conflicto.
    \item Propagación unitaria (llamado en inglés \textit{Unit Propagation}), en esta etapa se asignan valores a aquellos literales cuyo valor se pueden deducir. Es una de las mejoras clave del DPLL sobre su predecesor
    \item Análisis de conflicto: aquí se busca agregar restricciones adicionales basada en la asignación parcial en caso de hallar una contradicción
    \item Retroceso (comúnmente llamado \textit{Backtracking}), deshace asignaciones hechas en caso de darse una contradicción, para así explorar nuevos casos.\\
\end{enumerate}

\textbf{Ejemplo de SAT utilizando DPLL}\\

Considérese la siguiente fórmula en FNC:
$F=(A\lor \neg B)\land(B\lor C)\land(\neg A\lor \neg C)\land(\neg B\lor \neg A)\land(D\lor \neg C)\land(\neg A\lor D)$\\

Paso 1: Preprocesamiento
Se buscan literales puros. En este caso, como $\neg D$ no está presente en ninguna cláusula, se asigna $D=true$, reduciendo $F$ a:
$$F=(A\lor \neg B)\land(B\lor C)\land(\neg A\lor \neg C)\land(\neg B\lor \neg A)$$\\

Paso 2: Ramificación
El algoritmo DPLL selecciona un literal para asignar un valor. Supongamos que elegimos $A$ y lo asignamos a verdadero:
$A=true$\\

Paso 3: Propagación Unitaria
Después de asignar $A=true$, se actualiza la fórmula. La cláusula $(A\lor \neg B)$ se satisface y se elimina, por lo que $F$ se reduce a $(B\lor C)\land(\neg C)\land(\neg B)$
Ahora, se aprecian las cláusulas $(\neg C)$ y $(\neg B)$. Esto implica que $C=false$ y $B=false$. Sin embargo, esto hace falsa la segunda cláusula.\\

Paso 4: Análisis del conflicto.
Debido a que la asignación parcial conlleva a la cláusula vacía, se puede adicionar una nueva cláusula $(\neg A)$. Siendo ahora:
$$F=(A\lor \neg B)\land(B\lor C)\land(\neg A\lor \neg C)\land(\neg B\lor \neg A)\land(\neg A)$$\\

Paso 5: Retroceso
Se deshace la asignación $A=true$. Luego, al volver al paso 1 y ejecutar luego ejecutar el paso 2, se llega a que la asignación:
$A=false, B=false,C=true, D=true$\\

Haciendo $F$ satisfacible.

\subsection{Consistencia como forma de propagación de restricciones}

La mayoría de los algoritmos usados recaen en la propagación de restricciones (\textit{constraint propagation}) y se realiza mediante la comprobación de consistencia entre los valores de las variables. Es necesario precisar que el término consistencia utilizado en esta sección es diferente al usado en lógica, refiriéndose a la reducción de dominio de variables a aquellos valores que puedan pertenecer a una solución factible de un problema.\\

La forma más básica de consistencia es la consistencia de nodo, que se cumple si y solo si todos los valores del dominio de una variable cumplen con todas las restricciones unarias. Suponga que se tiene una variable $x \in \{1,2,...,50\}$. Si existe una restricción donde $x$ tiene que ser par, entonces al restringir el dominio de $x$ a $\{2,4,...,50\}$, se cumple la consistencia de nodo.\\

También se habla de la consistencia de arco, alcanzada al eliminar aquellos valores $a$ de una variable $x$ si no existen valores $b$ de una variable $y$ tales que $(a,b)$ satisfagan a todas las restricciones entre $x$ y $y$. Uno de los algoritmos más utilizados para alcanzar dicho estado es el algoritmo AC-3, el cual guarda todos los pares ordenados de variables en una cola. Luego saca iterativamente cada uno de estos pares $<x,y>$ hasta que la cola se quede vacía, y comprueba la consistencia de arco para cada posible valor de $x$. Si un valor no cumple la consistencia de arcos, este valor es eliminado del dominio de $x$, y todos los pares de variables de la forma $<z,x>$ son reinsertados en la cola. El algoritmo tiene una complejidad de tiempo en el peor de los casos de $O(ed^3 )$, donde $e$ es la cantidad de pares y $d$ es el tamaño de dominio más grande. Tras aplicar la consistencia de arco, pueden surgir tres posibles escenarios: si todos los dominios de las variables quedan con exactamente 1 valor (en cuyo caso la asignación es satisfacible), si un dominio queda vacío (en cuyo caso ocurriría una contradicción y se debe retroceder en una asignación) o si al menos un dominio queda con más de un posible valor, en cuyo caso se le debe asignar un valor y volver a realizar consistencia de arco.\\

Otras formas de consistencia existentes son la consistencia de camino y la $k$-consistencia. La consistencia de camino considera no solo las restricciones binarias entre pares de variables, sino también las relaciones a través de secuencias más largas de variables. Aquí, $u$ es un valor consistente de $x$ si para todo $y$ existe un $w$ tal que dado cualquier secuencia de variables $a_1, a_2, ... a_n$, con $a_1=x$ y $a_n=y$ tenga la secuencia de valores $v_1, v_2, ... v_n$ con $v_1=u$ y $v_n=w$ de forma que el par $<v_i,v_{i+1}>$ cumpla con todas las restricciones binarias entre $a_i$ y $a_{i+1}$, con $1\leq  i \leq  n$. Si bien la aplicación de la consistencia de camino garantiza un mayor nivel de consistencia que la consistencia del arco, todavía no es suficiente para resolver CSP en general. Esto significa que garantizando dicha consistencia, no todas las asignaciones garantizadas por esta son necesariamente soluciones satisfacibles. Por otra parte, la k-consistencia se logra al garantizar que cualquier asignación válida de valores a $k-1$ variables garantiza la posibilidad de asignación de un valor a cualquier otra variable. Se dice que se es fuertemente $k$-consistente si para todo $j<k$ se es $j$-consistente. Ambos tipos de consistencias son bastante costosos computacionalmente, por lo que no son muy utilizados en la práctica en comparación con la consistencia de arco.\\

\subsection{Restricciones globales de la programación de satisfacción de restricciones}

A diferencia de la programación en enteros, que restringe su modelado a expresiones lineales, en la programación por restricciones, los modelos suelen expresarse en forma de predicados, que si bien pudieran ser convertidos a modelos lineales, dicha conversión puede ser engorrosa. Dichos predicados suelen depender del software utilizado, y en muchos casos se da la oportunidad al usuario de definir predicados locales. Pero de forma general existen restricciones globales que suelen ser semánticamente redundantes y permiten filtrar el dominio de las variables.


\textbf{Restricciones globales fundamentales:}\\

\begin{itemize}
    \item \textbf{All Different}: Esta restricción fuerza a que todos los valores de las variables sean diferentes entre sí.
    \item \textbf{Global Cardinality}: Estas restricciones controlan la cantidad de veces que ciertos valores pueden aparecer en un conjunto de variables. Por ejemplo, global\_cardinality permite especificar cuántas veces debe aparecer cada valor en un \textit{array} de variables.
    \item \textbf{Inverse}: Esta restricción asegura que si un valor se asigna a una variable, entonces otro conjunto de variables debe reflejar esa asignación en un orden inverso. Es útil para problemas donde la relación entre las variables es crucial.
    \item \textbf{Table}: Permite definir restricciones basadas en una tabla predefinida que especifica combinaciones válidas de valores para un conjunto de variables. Esto es útil para modelar relaciones complejas entre variables.
    \item \textbf{Circuit}: Asegura que un conjunto de variables forma un circuito, lo cual es esencial en problemas como el Traveling Salesman Problem. Esta restricción garantiza que no haya subcircuitos y que todos los nodos sean visitados.
    \item \textbf{Lexicographic Order (Lex)}: Se utiliza para imponer un orden lexicográfico entre dos o más secuencias de variables, lo que puede ser útil en problemas donde el orden relativo es importante.
    \item \textbf{Element}: Esta restricción permite acceder a los elementos de un \textit{array} mediante índices definidos por otras variables, facilitando la modelización de problemas donde se necesita seleccionar entre múltiples opciones.
    \item \textbf{Cumulative}: Se utiliza para gestionar recursos limitados en el tiempo, asegurando que las demandas no excedan la capacidad disponible en cada momento.
    \item \textbf{Regular}: Permite definir restricciones sobre cadenas de longitud variable y es útil en problemas relacionados con autómatas y gramáticas formales.
    
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  EXPLICACIÓN DEL CÓDIGO                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementación}

Para llevar a cabo la comparación entre ambos paradigmas, fueron utilizadas las siguientes clases de problemas:
\begin{itemize}
\item \textbf{Bin Packing}: Dado una cantidad de objetos de diferentes tamaños determinar el menor número de agrupaciones que se pueden formar tal que la suma total dentro de un grupo no exceda cierto valor.
\item \textbf{K-Coloración}: determinar el número cromático de un grafo, en otras palabras, la menor cantidad de colores necesarios para colorear sus vértices sin que dos vértices vecinos (unidos por una arista) tengan el mismo color.
\item \textbf{Max-Clique}: hallar el mayor conjunto de vértices de un grafo tal que para todo par de vértices hay una arista que los une.
\item \textbf{Portfolio}: Dado un conjunto, determinar la combinación de cierta cantidad de subconjuntos de determinado tamaño que minimice la intersección 2 a 2 de dichos conjuntos.
\item \textbf{Set Cover}: Dado un conjunto y una lista de subconjuntos de este encontrar la menor cantidad entre los subconjuntos cuya unión resulte en el conjunto original.
\item \textbf{Traveling Salesman Problem (TSP)}: Dado un grafo ponderado completo, encontrar el ciclo simple que pase por todos los nodos tal que la suma de aristas sea mínima.
\item \textbf{Vehicle Routing Problem(VRP)}:  Hallar el conjunto óptimo de rutas para una flota de vehículos que debe satisfacer las demandas de un conjunto dado de clientes.
\item \textbf{The Job Shop Problem (JSP)}: Hallar la mínima cantidad de tiempo que hace falta para realizar un conjunto de trabajos sin que estos se solapen. Cada trabajo está caracterizado por un conjunto de tareas, las cuales deben hacerse en máquinas específicas.\\

\end{itemize}

Para la modelación de cada problema, se realizó un modelo por cada paradigma. Para esto se utilizó Ortools, que es un paquete de software de código abierto desarrollado por Google para resolver problemas complejos de optimización. Ortools facilita la comparación entre ambos paradigmas al ofrecer un entorno flexible y accesible para el modelado y la resolución de problemas. Para resolver los modelos de programación entera se usó la biblioteca pywraplp, mientras que para resolver los modelos de la programación de satisfacción de  restricciones se utilizó cp-model.\\

Para cada clase de problema, una vez implementada la solución genérica en ambos paradigmas, se simulan diferentes instancias de la clase y se guardan los tiempos empleados. Una vez con los tiempos medidos, se agrupan los problemas según propiedades a analizar, y se investiga una posible correlación entre el desempeño de cada solución y la propiedad.

\chapter{Resultados}
Presentar las pruebas que apoyan tales resultados cumplidos de los objetivos, sea en forma de figuras, tablas o en el mismo texto. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                       CONCLUSIONES                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusiones}
Se establece las conclusiones de cada asunto investigado, implicaciones para la teoría y resultados de las
experiencias. Estos siempre estarán en relaciona los objetivos generales y específicos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                       BIBLIOGRAFÍA                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}

\begin{thebibliography}{8}
\bibitem{ref_article1}
Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)

\bibitem{ref_lncs1}
Author, F., Author, S.: Title of a proceedings paper. In: Editor,
F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
Springer, Heidelberg (2016).

\bibitem{ref_book1}
Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
Location (1999)

\bibitem{ref_proc1}
Author, A.-B.: Contribution title. In: 9th International Proceedings
on Proceedings, pp. 1--2. Publisher, Location (2010)

\bibitem{ref_url1}
Oct 2017
\end{thebibliography}

\end{document}
